version: "3"

services:
  app:
    build:
      context: .
    ports:
      - "8000:8000"
    volumes:
      - ./app:/app
    command: >
     sh -c "python manage.py wait_for_db && 
            python manage.py migrate &&
            python manage.py runserver 0.0.0.0:8000" # call the wait_for_db cmd by calling manage.py; once db is available it'll run the runserver cmd to start the server, but first we'll run the db migrations on our db so it'll create any required tables for our app - good idea to run migrations first so we don't run into issues
    environment:
      - DB_HOST=db # when ur in the app service, u can connect to the hostname db & it'll connect to the container running on our db service
      - DB_NAME=app # must equal our postgres db - which is 'app'
      - DB_USER=postgres
      - DB_PASS=supersecretpassword
    depends_on:
      - db



  db:
    image: postgres:10-alpine 
    volumes:
      - "./local/path/to/postgres/data:/var/lib/postgresql/data"
    # ports:
    #   - "5432:5432"
     # gets the postgres image on dockerhub that has the tag 10-alpine
    environment: # documention shows the settings you can set via environment variables - we'll set some for the username, db name, & pw that's created when our db service starts
      - POSTGRES_DB=app # the postres container expects POSTGRES_DB to be all uppercase
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=supersecretpassword # wouldn't use the same pw here that you'd use on a production system; for production, on whatever is building your application like Travis or Jenkins - you'd add an encrypted variable that override this when you push your application


# consider adding a redis service 
